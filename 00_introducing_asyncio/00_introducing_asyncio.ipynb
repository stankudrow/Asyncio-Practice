{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83489f0c",
   "metadata": {},
   "source": [
    "# Introducing asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839d7ebb",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "\n",
    "* [The problems of sequential code](#sequential-problems)\n",
    "* [Concurrency](#concurrency)\n",
    "* [Threads and Processes](#threads-and-processes)\n",
    "* [The Global Interpreter Lock (GIL)](#gil)\n",
    "* [Python standard library concurrency modules](#stdlib)\n",
    "* [Hello, asyncio](#hello-asyncio)\n",
    "* [References](#refs)\n",
    "\n",
    "Here and after, the **Python v3.10** will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516564ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import inspect\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "import typing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cfaf3a",
   "metadata": {},
   "source": [
    "### The problems of sequential code <a class=\"anchor\" id=\"sequential-problems\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cf213f",
   "metadata": {},
   "source": [
    "The following snippet illustrates the performance of a sequential execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7564be76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R3 is sleeping for 1 seconds.\n",
      "R3 has woken up.\n",
      "R2 is sleeping for 3 seconds.\n",
      "R2 has woken up.\n",
      "R1 is sleeping for 1 seconds.\n",
      "R1 has woken up.\n",
      "Results = [1, 59049, 1]\n",
      "Elapsed time: 5.0\n"
     ]
    }
   ],
   "source": [
    "def routine(name: str) -> int:\n",
    "    \"\"\"A short description of the routine.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        the name of routine\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        sleep_time ** 10\n",
    "    \"\"\"\n",
    "    sleep_time: int = random.randint(1, 5)\n",
    "    print(f\"{name} is sleeping for {sleep_time} seconds.\")\n",
    "    time.sleep(sleep_time)\n",
    "    print(f\"{name} has woken up.\")\n",
    "    return sleep_time**10\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "results = [routine(f\"R{i}\") for i in range(3, 0, -1)]\n",
    "print(f\"Results = {results}\")\n",
    "print(f\"Elapsed time: {round(time.time() - start, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac90be6",
   "metadata": {},
   "source": [
    "Iterations and function calls are executed sequentially: the next one waits for the completion of the previous one. This is a case of **synchronous** programming when the instructions are executed in the strict order as they are written in the code.\n",
    "\n",
    "It would be great if each function could run separately and independently of the others. This would save precious time and resources and such a goal can be achieved with **concurrency**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed8f013",
   "metadata": {},
   "source": [
    "### Concurrency <a class=\"anchor\" id=\"concurrency\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032315aa",
   "metadata": {},
   "source": [
    "Before diving into the depths of concurrency, let's go through the shallow waters of multitasking.\n",
    "\n",
    "[**Multitasking**](https://en.wikipedia.org/wiki/Computer_multitasking) is the ability to perform multiple tasks over a certain period of time and can share the same resources. In computer science, tasks are running instances of programs (roughly speaking, processes) controlled by the operating system (OS).\n",
    "\n",
    "There are two major types of multitasking:\n",
    "\n",
    "* [preemptive](https://en.wikipedia.org/wiki/Preemption_(computing)) - the OS takes over switching between tasks/processes via the \\[task\\] scheduler (a module of the OS);\n",
    "\n",
    "* [cooperative](https://en.wikipedia.org/wiki/Cooperative_multitasking) - switch points, where a running task/process \"releases/acquires\" ([yields](https://en.wikipedia.org/wiki/Yield_(multithreading))) control, are explicitly written in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f2a04b",
   "metadata": {},
   "source": [
    "[**Concurrency**](https://en.wikipedia.org/wiki/Concurrency_(computer_science)) is the ability to do multiple tasks and switching between them, so concurrency is multitasking. The switching is done so fast, that we think the tasks are executed simultaneously. A good everyday example was given in the Matthew Fowler's book \"[Python concurrency with asyncio](https://www.amazon.com/Python-Concurrency-asyncio-Matthew-Fowler/dp/1617298662)\".\n",
    "\n",
    "![Concurrency/Parallelism illustration](img/concurrency_and_parallelism_illustration.png \"Concurrency/Parallelism illustration\")\n",
    "\n",
    "Concurrency should be distinguished from [parallelism](https://en.wikipedia.org/wiki/Parallel_computing) when tasks start, run, and complete independently. Parallelism is achieved only on a multicore machine: a core per task is a sort of an isolated swimline. In terms of parallelism, a task can be likened to a swimmer who passes the distance at his own speed (usually) without interfering with other competitors. On a single-core machine, only concurrency is supportable.\n",
    "\n",
    "![Concurrency/Parallelism switching](img/concurrency_and_parallelism_switching.png \"Concurrency/Parallelism switching\")\n",
    "\n",
    "Parallelism implies (is a subset of) concurrency, i.e. multiple tasks are done at the same time, but concurrency does not imply (is a superset of) parallelism (a single-core case). The [image](https://realpython.com/async-io-python/) below depicts this relation:\n",
    "\n",
    "![Concurrency/Parallelism relationship](img/concurrency_and_parallelism_venn_diagram.webp \"Concurrency/Parallelism relationship\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f78101",
   "metadata": {},
   "source": [
    "The following [picture](https://dsin.wordpress.com/2017/08/28/different-between-concurrency-and-parallelism/) visualises the sequential, concurrent and parallel ways of execution flows:\n",
    "\n",
    "* sequential - a deterministic order of execution;\n",
    "* concurrent - out of the order (switching, not necessarily equally done);\n",
    "* parallel - an separate and independent execution of a task.\n",
    "\n",
    "![Sequential, Concurrent and Parallel ways depicted](img/execution_flows.jpeg \"Sequential, Concurrent and Parallel ways\")\n",
    "\n",
    "Parallel and concurrent models are the examples of **asynchronous** programming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12acbb2",
   "metadata": {},
   "source": [
    "### Threads and Processes <a class=\"anchor\" id=\"threads-and-processes\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c878c",
   "metadata": {},
   "source": [
    "In the [concurrency](#concurrency) chapter tasks were deliberately called processes. Now consider the concept of process in more detail.\n",
    "\n",
    "A [process](https://en.wikipedia.org/wiki/Process_(computing)) refers to a running instance of a computer program isolated from other processes on the same machine. Every process has the main thread which executes program instructions. A running Python program is an instance of the Python interpreter carrying out Python instructions (Python byte-code).\n",
    "\n",
    "A [thread](https://en.wikipedia.org/wiki/Thread_(computing)) is the object of the OS - the smallest sequence of programmed instructions - that executes the instructions of a process. A thread can be managed independently by the OS scheduler. By default, a process has the main thread, but a process can spawn inside itself multiple threads that can execute independently instructions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b530ae",
   "metadata": {},
   "source": [
    "In a [nutshell](https://www.baeldung.com/cs/process-vs-thread):\n",
    "\n",
    "* a thread is like a virtual processor (core), a process is like a virtual computer;\n",
    "\n",
    "* each process has at least one thread and no thread lives outside any process;\n",
    "\n",
    "* creating a thread is cheaper than a process;\n",
    "\n",
    "* threads can share the resources assigned to the process that spawned them;\n",
    "\n",
    "* spawned ([forked](https://en.wikipedia.org/wiki/Fork_(system_call))) processes are isolated copies that have not shareable resources;\n",
    "\n",
    "* a process and a thread are objects to the task scheduler, so they can both be called tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e21f1",
   "metadata": {},
   "source": [
    "### The Global Interpreter Lock (GIL) <a class=\"anchor\" id=\"gil\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38bff1",
   "metadata": {},
   "source": [
    "The Python Global Interpreter Lock or GIL is a sort of mutex (in Python, [lock](https://en.wikipedia.org/wiki/Lock_(computer_science))) that allows only one thread be running at any time. In short, a mutex is a synchronisation primitive (~tool) that manages the access of concurrent tasks (threads or processes) to shareable resources. The GIL protects access to Python objects, preventing multiple threads from executing Python bytecodes at once.\n",
    "\n",
    "For single-threaded programs, the GIL is not a problem, but is a significant hindrance for concurrent programs. When a thread runs, first it acquires the GIL. Other threads cannot acquire the GIL until it is released, so instead of doing job, they are seeking to acquire the Lock. Therefore, the benefits of concurrency are nullified.\n",
    "\n",
    "If so, why the GIL was incorporated into Python? The key reason is that CPython's (the implementation of Python in C programming language) memory management is not thread-safe. Python uses reference counting for memory menagement. When a Python object is created, it has a referece count variable that keeps track of the number of references that point to the object. When the refcount variable of an object reaches zero, the object if free'd from the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1bcdd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty structures\n",
      "obj: refcount = 2\n",
      "lst: refcount = 2\n",
      "\n",
      "lst.append(obj)\n",
      "lst: refcount = 2\n",
      "obj: refcount = 3\n",
      "\n",
      "del lst[0]: refcount = 2\n"
     ]
    }
   ],
   "source": [
    "obj = object()\n",
    "lst = []\n",
    "print(\"Empty structures\")\n",
    "print(f\"obj: refcount = {sys.getrefcount(obj)}\")\n",
    "print(f\"lst: refcount = {sys.getrefcount(lst)}\\n\")\n",
    "\n",
    "lst.append(obj)\n",
    "print(\"lst.append(obj)\")\n",
    "print(f\"lst: refcount = {sys.getrefcount(lst)}\")\n",
    "print(f\"obj: refcount = {sys.getrefcount(obj)}\\n\")\n",
    "\n",
    "del lst[0]\n",
    "print(f\"del lst[0]: refcount = {sys.getrefcount(lst)}\")\n",
    "\n",
    "# See https://docs.python.org/3/library/sys.html#sys.getrefcount\n",
    "# for an explanation why `sys.getrefcount` returns 2 for an empty list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9471068b",
   "metadata": {},
   "source": [
    "Suppose that:\n",
    "\n",
    "* PyObj is a Python object with a refcount variable equal to 1;\n",
    "* T1 is a thread that increments (+1) the PyObj refcount value;\n",
    "* T2 is a thread that decrements (-1) the PyObj refcount value.\n",
    "\n",
    "A golden rule of concurrency is that you ***can never be sure what order of execution will be carried out since it is an out-of-order technique done in overlapping and interleaving fashion***. So we can have possible situations:\n",
    "\n",
    "Situation 1:\n",
    "\n",
    "1. T1 &rarr; PyObj.refcount = 2\n",
    "2. T2 &rarr; Pyobj.refcount = 1\n",
    "\n",
    "In the situation 1 a PyObj lives but maybe it should have been deleted, so it may be a problem.\n",
    "\n",
    "Situation 2:\n",
    "\n",
    "<ol>\n",
    "    <li>T2 &rarr; PyObj.refcount = 0</li>\n",
    "    <li>and now there are troubles on the horizon...</li>\n",
    "    <ol>\n",
    "        <li>T1 got the job done &rarr; PyObj.refcount = 1 - but maybe this result is not desirable.</li>\n",
    "        <li>The <a href=\"https://rushter.com/blog/python-garbage-collector/\">garbage collector</a> - memory \"janitor\" module - managed to free the PyObj &rarr; this memory area is no longer valid to be addressed &rarr; error-prone undefined behaviour leading to possible system corruption.</li>\n",
    "    </ol>\n",
    "</ol>\n",
    "    \n",
    "Such problems of concurrency are called [race conditions](https://www.baeldung.com/cs/race-conditions). A **race condition** is a condition of a program where its behaviour depends on relative timing or interleaving of multiple threads or processes. It is the case when the indeterministic interleaving between tasks make the outcome of a program unpredictable which is not optative.\n",
    "\n",
    "![Race conditions](img/race_conditions_with_refcount.png \"Race conditions with refcount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df234b8b",
   "metadata": {},
   "source": [
    "It was because of the need to manage memory and solve the problems of concurrent code that the GIL was created. Adding the GIL in this implementation was a pragmatic solution ещё и по for the following reasons:\n",
    "\n",
    "* easy to integrate C libraries/extensions, including thread-unsafe, since the GIL will take care about consistency;\n",
    "\n",
    "* one lock is a cheap and simple enough solution that does not complicate the support of the Python language;\n",
    "\n",
    "* multi-core computers is a relatively new concept to be widely spreaded ([article](https://medium.com/pyslackers/lets-talk-about-python-s-gil-ade59022bc83))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430fa1bb",
   "metadata": {},
   "source": [
    "### Python standard library concurrency modules <a class=\"anchor\" id=\"stdlib\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222a7054",
   "metadata": {},
   "source": [
    "The Python Standard Library provides modules to enjoy concurrency powers:\n",
    "\n",
    "* `threading`\n",
    "\n",
    "\n",
    "* `multiprocessing`\n",
    "\n",
    "\n",
    "* `asyncio`\n",
    "\n",
    "A nice and simple answer on which module to choose was given in the [Stack Overflow](https://stackoverflow.com/questions/27435284/multiprocessing-vs-multithreading-vs-asyncio)\n",
    "\n",
    "```python\n",
    "if io_bound:\n",
    "    if slow_io:  # many connections\n",
    "        print(\"Use asyncio\")\n",
    "    else:  # fast I/O, a limited number of connections\n",
    "        print(\"Use threading\")\n",
    "else:  # cpu_bound\n",
    "    print(\"Use multiprocessing\")\n",
    "```\n",
    "\n",
    "**Note**: The `concurrent.futures` module provides fancy abstractions over `multithreading` or `multiprocessing` packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571922d5",
   "metadata": {},
   "source": [
    "In Python, it is important to distinct CPU-bound (*determined by the speed of the CPU*) and I/O-bound (*determined by the speed of I/O devices*) operations.\n",
    "\n",
    "Because Python interpreter uses the GIL, a single-process Python program could only use one native thread during execution without exploiting CPU more than 100%, i.e. without enjoying multi-core utilisation. Is there a way to bypass such a huge limitation?! In short, yes &rarr; to create multiple processes, each holding its own GIL since they are instances of Python programs, each exploiting a CPU core assigned to it.\n",
    "\n",
    "![Spawning Python interpreters](img/python_multiprocessing.png \"Spawning Python interpreters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19314ed",
   "metadata": {},
   "source": [
    "Creating processes is not a cheap solution, but for CPU-bound tasks it is the way. Creating threads is less expensive than spawning processes, but using threads in Python for solving CPU-bound tasks is (usually) a bad idea, but (maybe) a good idea for I/O-bound operations. The point is that in case of I/O operations the GIL is [released](https://stackoverflow.com/questions/36949042/when-the-gil-is-released).\n",
    "\n",
    "All right, let's check this out in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b75bba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a decorating function, ot a decorator\n",
    "def named_timer(name: str = \"func\"):\n",
    "    def timer(func: typing.Callable):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start = time.time()\n",
    "            res = func(*args, **kwargs)\n",
    "            end = round(time.time() - start, 2)\n",
    "            print(f\"{name} elapsed time: {end}\")\n",
    "            return res\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return timer\n",
    "\n",
    "\n",
    "# @named_timer(\"squares\")\n",
    "def cpu_bound(start: int, end: int, step: int):\n",
    "    return sum([num**2 for num in range(start, end, step)])\n",
    "\n",
    "\n",
    "# @named_timer(\"sleeping\")\n",
    "def io_bound(sleep_time):\n",
    "    time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ae985b",
   "metadata": {},
   "source": [
    "Try uncommenting the decorators and see what happens - this notebook is a playground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0064bcd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squares elapsed time: 3.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "333333283333335000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CPU-bound work performed sequentially\n",
    "\n",
    "named_timer(\"Squares\")(cpu_bound)(1, 10000000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b82c36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 elapsed time: 0.06\n",
      "T2 elapsed time: 3.23\n",
      "CPU-bound work time: 3.239287853240967\n"
     ]
    }
   ],
   "source": [
    "# threads for the CPU-bound work\n",
    "\n",
    "t1 = threading.Thread(\n",
    "    target=named_timer(\"T1\")(cpu_bound), args=(1, 100000, 1)\n",
    ")\n",
    "t2 = threading.Thread(\n",
    "    target=named_timer(\"T2\")(cpu_bound),\n",
    "    args=(100000, 10000000, 1),\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# launching the threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# waiting for the threads until they are done\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "print(f\"CPU-bound work time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2cfd34",
   "metadata": {},
   "source": [
    "If you launch the cells with sequential and \"concurrent\" code, a strange behaviour will be exposed: ***threads do not show a stable gain in performance!*** Sometimes they work faster, sometimes slower comparing to the sequential code above.\n",
    "\n",
    "What will happen in case of I/O operations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03aa4871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleepy_1 elapsed time: 1.0\n",
      "Sleepy_2 elapsed time: 2.0\n",
      "I/O-bound work time: 3.0023934841156006\n"
     ]
    }
   ],
   "source": [
    "# I/O-bound work performed sequentially\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "named_timer(\"Sleepy_1\")(io_bound)(1)\n",
    "named_timer(\"Sleepy_2\")(io_bound)(2)\n",
    "\n",
    "print(f\"I/O-bound work time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d21eed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 elapsed time: 1.0\n",
      "T2 elapsed time: 2.0\n",
      "I/O-bound work time: 2.003573179244995\n"
     ]
    }
   ],
   "source": [
    "# threads for the I/O-bound work\n",
    "\n",
    "t1 = threading.Thread(\n",
    "    target=named_timer(\"T1\")(io_bound), args=(1,)\n",
    ")\n",
    "t2 = threading.Thread(\n",
    "    target=named_timer(\"T2\")(io_bound), args=(2,)\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "print(f\"I/O-bound work time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8418dca4",
   "metadata": {},
   "source": [
    "Lovely! In case of I/O-bound work we do see some increase in performance. It is an illustrative demonstration of the concurrency in Python and the impact of the GIL. So we do need to choose wisely at least when "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7db833",
   "metadata": {},
   "source": [
    "**Note**. Attentive readers may notice that the starting and joining threads phases can be combined in one loop, so why not to improve and refactor the code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c13abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1_imp elapsed time: 1.0\n",
      "T2_imp elapsed time: 2.0\n",
      "I/O-bound improved (?) work time: 3.0038859844207764\n"
     ]
    }
   ],
   "source": [
    "# refactored threading\n",
    "\n",
    "threads = [\n",
    "    threading.Thread(\n",
    "        target=named_timer(\"T1_imp\")(io_bound), args=(1,)\n",
    "    ),\n",
    "    threading.Thread(\n",
    "        target=named_timer(\"T2_imp\")(io_bound), args=(2,)\n",
    "    ),\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "    thread.join()\n",
    "\n",
    "print(f\"I/O-bound improved (?) work time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15df506",
   "metadata": {},
   "source": [
    "Aight, actually, it can be frustrating because the threads will stop executing concurrently. The reason is that if you start and join a thread in the same iteration, the latter will block execution until the thread finishes. Accordingly, the threads at the next iteration simply will not be able to start until the previous iteration is completed. That is why starting and joining threads should be done separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80ca7b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1_imp elapsed time: 1.0\n",
      "T2_imp elapsed time: 2.0\n",
      "I/O-bound improved (!) work time: 2.0030434131622314\n"
     ]
    }
   ],
   "source": [
    "# re-refactored threading\n",
    "\n",
    "threads = [\n",
    "    threading.Thread(\n",
    "        target=named_timer(\"T1_imp\")(io_bound), args=(1,)\n",
    "    ),\n",
    "    threading.Thread(\n",
    "        target=named_timer(\"T2_imp\")(io_bound), args=(2,)\n",
    "    ),\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(f\"I/O-bound improved (!) work time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c3c5ba",
   "metadata": {},
   "source": [
    "### Hello, asyncio <a class=\"anchor\" id=\"hello-asyncio\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5588eddf",
   "metadata": {},
   "source": [
    "The `asyncio` module was first introduced in Python 3.4 and stands for \"Asynchronous I/O\". It uses a single-threaded (thanks to the GIL) event loop model for executing awaitable objects, e.g. coroutines.\n",
    "\n",
    "The term \"coroutine\" may refer to:\n",
    "\n",
    "* A **coroutine function** is an `async def` function which returns a coroutine object whereas a routine (an ordinary `def` function) returns a value (by default, `None`);\n",
    "\n",
    "* A **[coroutine object](https://docs.python.org/3/glossary.html#term-coroutine)** is a function with a superpower to be entered, exited, and resumed at many different points. Whereas for routines there is only one entry point (function call) and one exit point (the first return statement hit) and between them the work of the routine blocks the execution flow.\n",
    "\n",
    "See [PEP492](https://peps.python.org/pep-0492/) that introduced coroutines with `async`/`await` syntax.\n",
    "\n",
    "The [event loop](https://www.pythontutorial.net/python-concurrency/python-event-loop/) manages coroutines (a special case of expected objects): registration, status polling, deletion. For now, we will not go into details of how it works: first we will learn how to use it, and then we can crawl under the hood.\n",
    "\n",
    "![The illustration of event loop pattern](img/python-event-loop.svg \"The Event Loop\")\n",
    "\n",
    "\n",
    "Looking ahead, `asyncio` can be used not only for I/O-bound work, but also for CPU-bound, but it will be covered later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4cef60",
   "metadata": {},
   "source": [
    "Let's start with a simple one: since there are coroutines, then there can be routines. This is true, and routines are just regular Python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1984ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is routine? True\n",
      "Coroutine is sleeping for 1 second[s].\n",
      "Routine called = hello, routine.\n"
     ]
    }
   ],
   "source": [
    "def routine(sleep_time: int = 1) -> str:\n",
    "    print(f\"Coroutine is sleeping for {sleep_time} second[s].\")\n",
    "    time.sleep(sleep_time)\n",
    "    return \"hello, routine.\"\n",
    "\n",
    "\n",
    "print(f\"Is routine? {inspect.isroutine(routine)}\")\n",
    "ro_res = routine()\n",
    "print(f\"Routine called = {ro_res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f864ac",
   "metadata": {},
   "source": [
    "As expected, the routine is called, is executed till the return statement and the result is conveyed back.\n",
    "\n",
    "Let's try to do something similar with coroutines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "614beb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is coroutine? False\n",
      "Coroutine called = <coroutine object coroutine at 0x7f8d0920e340>\n",
      "Coroutine is sleeping for 1 second[s].\n",
      "Coroutine awaited = Hello, coroutine.\n"
     ]
    }
   ],
   "source": [
    "async def coroutine(sleep_time: int = 1) -> str:\n",
    "    print(f\"Coroutine is sleeping for {sleep_time} second[s].\")\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    return \"Hello, coroutine.\"\n",
    "\n",
    "\n",
    "print(f\"Is coroutine? {inspect.iscoroutine(coroutine)}\")\n",
    "coro_called = coroutine()\n",
    "print(f\"Coroutine called = {coro_called}\")\n",
    "coro_awaited = await coro_called\n",
    "print(f\"Coroutine awaited = {coro_awaited}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd16114",
   "metadata": {},
   "source": [
    "When a *coroutine function* is called, it returns a *coroutine object*. To get the result of a coroutine, it should be `await`'ed. If a coroutine is invoked but not awaited, you can get RuntimeWarning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c32f87c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17164/3514431137.py:5: RuntimeWarning: coroutine 'f' was never awaited\n",
      "  f()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "async def f():\n",
    "    await asyncio.sleep(1)\n",
    "\n",
    "\n",
    "f()\n",
    "await f()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d54adbe",
   "metadata": {},
   "source": [
    "Inside the routines `await` statements are not allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47ecebca",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'await' outside async function (1940803628.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    await asyncio.sleep(1)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'await' outside async function\n"
     ]
    }
   ],
   "source": [
    "def error_routine():\n",
    "    \"\"\"await is allowed only in async functions (coroutines).\"\"\"\n",
    "    await asyncio.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c801eb",
   "metadata": {},
   "source": [
    "Our \"Hello, asyncio\" example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8699244",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    print(routine())\n",
    "    print(await coroutine())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12aadf65",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04500665",
   "metadata": {},
   "source": [
    "Since Jupyter Notebook already has a running event loop, consider to run `00_hello_asyncio.py` script.\n",
    "\n",
    "To reproduce the example here, just awaiting the `main` coroutine **object** (!) will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0c7de1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coroutine is sleeping for 1 second[s].\n",
      "hello, routine.\n",
      "Coroutine is sleeping for 1 second[s].\n",
      "Hello, coroutine.\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3232a3cd",
   "metadata": {},
   "source": [
    "### References <a class=\"anchor\" id=\"refs\"></a>\n",
    "\n",
    "* Multitasking, concurrency, parallelism:\n",
    "    * [Web MIT Concurrency](https://web.mit.edu/6.005/www/fa14/classes/17-concurrency/)\n",
    "    * [Python threading, multiprocessing, asyncio](https://medium.com/@jersobh/python-optmized-parallelism-multiprocessing-e-asyncio-5b62f67e3ea3)\n",
    "    * [Concurrency and Parallelism - difference](https://stackoverflow.com/questions/1050222/what-is-the-difference-between-concurrency-and-parallelism)\n",
    "    * [Concurrency vs Parallelism](https://www.baeldung.com/cs/concurrency-vs-parallelism)\n",
    "    * [Concurrency is not Parallelism](https://www.youtube.com/watch?v=oV9rvDllKEg) by Rob Pike \n",
    "\n",
    "* Python concurrency modules:\n",
    "    * [Superfast Python - threading](https://superfastpython.com/threading-in-python/)\n",
    "    * [Superfast Python - multiprocessing](https://superfastpython.com/multiprocessing-in-python/)\n",
    "    * [Superfast Python - asyncio](https://superfastpython.com/python-asyncio/)\n",
    "\n",
    "* The Global Interpreter Lock (GIL):\n",
    "    * [Real Python - GIL](https://realpython.com/python-gil/)\n",
    "    * [Python Wiki - GIL](https://wiki.python.org/moin/GlobalInterpreterLock)\n",
    "\n",
    "* David Beazley Talks:\n",
    "    * [Understanding the Python GIL](https://www.youtube.com/watch?v=Obt-vMVdM8s)\n",
    "    * [Embracing the GIL](https://www.youtube.com/watch?v=fwzPF2JLoeU)\n",
    "    * [Inside the Python GIL](https://www.youtube.com/watch?v=ph374fJqFPE)\n",
    "    \n",
    "* Asyncio related:\n",
    "    * [\"Python concurrency with asyncio\", Matthew Fowler](https://www.amazon.com/Python-Concurrency-asyncio-Matthew-Fowler/dp/1617298662)\n",
    "    * [PEP-492](https://peps.python.org/pep-0492/) - coroutines with async/await syntax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
